"""Implementaci√≥n del worker MRL-AMIS que usa dataclasses de dominio."""

import logging
import time
from datetime import datetime
from typing import Any, Dict

import numpy as np
import pandas as pd

from bucle_principal_mrl_amis.bucle_iterativo_mrl_amis import (
    calculate_average_ratio_pareto, calculate_hypervolume, 
    find_pareto_front, spacing_metric, update_population
)
from estado_y_recompensa_rl.definir_comportamiento import calculate_reward, get_state
from intelligence_boxes.definir_intelligence_boxes import (
    ib_diversity_mutation, ib_guided_perturbation, ib_inversion_mutation, 
    ib_local_search, ib_random_perturbation, ib_swap_mutation
)
from grpc_queue.data_mappers import build_domain_payload
from runmodel.models.data_generator import generate_synthetic_data
from AgenteQLearning.QLearningAgent import QLearningAgent
from generacionWorkPackages.workPackages import generar_work_packages, decodificar_wp
from generacionWorkPackages.funcionesObjetivo import evaluar_funciones_objetivo

logger = logging.getLogger(__name__)


class DomainMRLAMISWorker:
    """Worker que usa dataclasses de dominio para ejecutar MRL-AMIS."""
    
    def __init__(self):
        """Inicializar el worker de optimizaci√≥n de rutas"""
        logger.info("Inicializando DomainMRLAMISWorker...")
        
        # Configuraci√≥n predeterminada del modelo MRL-AMIS
        self.default_config = {
            'num_work_packages': 105,  # INCREASED: 100 -> 105 (+5 work packages)
            'max_iterations': 100,
            'num_pois': 15,
            'max_pois_per_route': 100000,
            'min_pois_per_route': 2,
            'num_routes_per_wp': 3,
            'max_duration_per_route': 720,
            'maximize_objectives_list': [True, False, False, True, False],
            'ref_point_hypervolume': [0, 1000, 1000, -1000, 1000]
        }
        
        # Configuraci√≥n del agente RL
        self.rl_config = {
            'state_space_size': 7,
            'action_space_size': 6,
            'learning_rate': 0.2,
            'discount_factor': 0.85,
            'epsilon_start': 1.0,
            'epsilon_decay_rate': 0.995,
            'min_epsilon': 0.15
        }
        
        # Intelligence Boxes disponibles
        self.intelligence_boxes = {
            0: ib_random_perturbation,
            1: ib_swap_mutation,
            2: ib_inversion_mutation,
            3: ib_guided_perturbation,
            4: ib_local_search,
            5: ib_diversity_mutation
        }
        
        logger.info("DomainMRLAMISWorker inicializado correctamente")

    def execute_optimization(
        self,
        job_data: Dict[str, Any], 
        request_data: Dict[str, Any], 
        job_id: str, 
        progress_callback=None
    ) -> Dict[str, Any]:
        """Ejecuta optimizaci√≥n usando el mapeo completo a dataclasses."""
        
        try:
            start_time = time.time()
            logger.info(f"Iniciando optimizaci√≥n MRL-AMIS con dataclasses para trabajo {job_id}")
            
            if progress_callback:
                progress_callback(job_id, 5.0, "Inicializando mapeo de datos...")

            # 1. Mapear request_data a dataclasses de dominio
            domain_payload = build_domain_payload(
                job_data=job_data,
                request_data=request_data,
                default_group_id=f"group_{job_id[:8]}"
            )
            
            if progress_callback:
                progress_callback(job_id, 15.0, f"Mapeados {len(domain_payload.pois)} POIs y grupo tur√≠stico")

            # 2. Generar datos sint√©ticos adicionales si es necesario
            synthetic_data = generate_synthetic_data(num_pois=len(domain_payload.pois), seed=42)
            
            if progress_callback:
                progress_callback(job_id, 25.0, "Generados datos sint√©ticos complementarios")

            # 3. Estructuras de datos para MRL-AMIS
            data = self._prepare_mrl_amis_data(domain_payload, synthetic_data)
            
            if progress_callback:
                progress_callback(job_id, 35.0, "Preparadas estructuras MRL-AMIS")

            # 4. Informaci√≥n del grupo adaptada
            grupo_info = self._create_grupo_info_from_domain(domain_payload)
            data['grupo_info'] = grupo_info
            
            if progress_callback:
                progress_callback(job_id, 45.0, "Configurado grupo tur√≠stico")

            # 5. Ejecutar algoritmo MRL-AMIS
            result = self._execute_mrl_amis_core(
                data, domain_payload, progress_callback, job_id
            )
            
            execution_time = time.time() - start_time
            result['execution_time_seconds'] = execution_time
            result['generated_at'] = datetime.now().isoformat()
            
            if progress_callback:
                progress_callback(job_id, 100.0, "Optimizaci√≥n completada exitosamente")
            
            logger.info(f"Optimizaci√≥n MRL-AMIS completada para trabajo {job_id} en {execution_time:.2f} segundos")
            return result
            
        except Exception as e:
            logger.error(f"Error en optimizaci√≥n MRL-AMIS para trabajo {job_id}: {str(e)}")
            if progress_callback:
                progress_callback(job_id, 0.0, f"Error: {str(e)}")
            raise e

    def _prepare_mrl_amis_data(
        self, 
        domain_payload, 
        synthetic_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Prepara las estructuras de datos necesarias para MRL-AMIS."""
        
        # Usar DataFrames del domain_payload
        data = {
            'pois': domain_payload.pois_dataframe,
            'distances': domain_payload.distance_matrix,
            'travel_times': domain_payload.travel_time_matrix,
            'preferencias_grupos_turistas': domain_payload.group_preferences_matrix,
        }
        
        logger.info(
            f"DataFrame POIs: {data['pois'].shape}, "
            f"Distance Matrix: {data['distances'].shape}, "
            f"Travel Time Matrix: {data['travel_times'].shape}"
        )
        
        # Agregar matrices sint√©ticas adicionales del generador
        for key in ['costs', 'co2_emission_cost', 'accident_risk', 'costos_experiencia']:
            if key in synthetic_data:
                data[key] = synthetic_data[key]
                
            # COSTOS DE EXPERIENCIA: Crear tabla con estructura correcta
        if 'costos_experiencia' in synthetic_data:
            costos_exp = synthetic_data['costos_experiencia']
            
            # Si es DataFrame, verificar que tenga los POI IDs como √≠ndice
            if isinstance(costos_exp, pd.DataFrame):
                # Reindexar si es necesario
                poi_ids = [poi.id for poi in domain_payload.pois]
                if list(costos_exp.index) != poi_ids:
                    logger.info(f"Reindexando costos_experiencia para coincidir con POI IDs")
                    # Crear nuevo DataFrame con √≠ndices correctos
                    costos_exp_reindexed = pd.DataFrame(
                        costos_exp.values[:len(poi_ids)],
                        index=poi_ids,
                        columns=costos_exp.columns
                    )
                    data['costos_experiencia'] = costos_exp_reindexed
                else:
                    data['costos_experiencia'] = costos_exp
                
                logger.info(f"Costos de experiencia agregados:")
                logger.info(f"  -> Shape: {data['costos_experiencia'].shape}")
                logger.info(f"  -> √çndices (POI IDs): {data['costos_experiencia'].index.tolist()}")
                logger.info(f"  -> Columnas: {data['costos_experiencia'].columns.tolist()}")
                
        params = synthetic_data.get('parametros_generales')
        if params is not None and isinstance(params, dict):
            data['parametros_generales'] = pd.DataFrame.from_dict(params, orient='index', columns=['Valor'])
        else:
            logger.warning("‚ö†Ô∏è  PAR√ÅMETROS GENERALES NO DISPONIBLES")
        
        # Par√°metros generales
        data['parametros_generales'] = synthetic_data.get('parametros_generales', {})
        logger.info(f"Par√°metros generales agregados: {len(data['parametros_generales'])} par√°metros")
        logger.info(f"Par√°metros generales: {data['parametros_generales']}")
        
        return data

    def _create_grupo_info_from_domain(self, domain_payload) -> Dict[str, Any]:
        """Crea informaci√≥n del grupo basada en el TouristGroup."""
        
        group = domain_payload.tourist_group

        return {
            'tiempo_disponible': group.tiempo_disponible_min,
            'presupuesto': group.presupuesto_max_usd,
            'tipo_turista': group.tipo_turista,
            'sostenibilidad_min': group.sostenibilidad_min,
            'nivel_aventura': group.nivel_aventura,
            'conciencia_ambiental': group.conciencia_ambiental,
            'tolerancia_riesgo': group.tolerancia_riesgo,
            'origen': group.origen,
            'destino': group.destino,
            'min_pois_per_route': 1,
            'max_pois_per_route': min(10, len(domain_payload.pois)),
            'preferencias_tipos': group.preferencias_tipos
        }

    def _log_input_data(
        self, 
        domain_payload, 
        data: Dict[str, Any], 
        job_id: str
    ):
        """Registra detalladamente los datos de entrada."""
        
        logger.info("=" * 80)
        logger.info(f"INICIANDO MRL-AMIS CORE - JOB ID: {job_id}")
        logger.info("=" * 80)
        
        # Log POIs
        logger.info(f"\nPOIs RECIBIDOS ({len(domain_payload.pois)} total)")
        for i, poi in enumerate(domain_payload.pois, 1):
            logger.info(
                f"POI {i}: ID={poi.id}, Nombre={poi.name}, "
                f"Pos=({poi.position[0]:.4f}, {poi.position[1]:.4f})"
            )


        # Log grupo tur√≠stico
        group = domain_payload.tourist_group
        logger.info(f"\nGRUPO TUR√çSTICO:")
        logger.info(f"  ID: {group.grupo_id}")
        logger.info(f"  Tipo: {group.tipo_turista}")
        logger.info(f"  Presupuesto: ${group.presupuesto_max_usd}")
        logger.info(f"  Tiempo: {group.tiempo_disponible_min} min")
        logger.info(f"  Origen: {group.origen} -> Destino: {group.destino}")
        
        # Log matrices
        self._log_matrix(data.get('distances'), "DISTANCIAS (km)")
        self._log_matrix(data.get('travel_times'), "TIEMPOS DE VIAJE (min)")
        self._log_matrix(data.get('costs'), "COSTOS (USD)")
        self._log_matrix(data.get('co2_emission_cost'), "EMISIONES CO2 (kg)")
        self._log_matrix(data.get('accident_risk'), "RIESGO DE ACCIDENTES")
        self._log_matrix(data.get('preferencias_grupos_turistas'), "Preferencias Grupo-POI")
        self._log_matrix(data.get('costos_experiencia'), "COSTOS DE EXPERIENCIA (USD)")

    def _log_matrix(self, matrix, title: str):
        """Registra una matriz con estad√≠sticas."""
        
        logger.info(f"\n{'='*80}")
        logger.info(title)
        logger.info(f"{'='*80}")
        
        if matrix is not None:
            logger.info(f"Dimensiones: {matrix.shape}")
            if hasattr(matrix, 'to_string'):
                logger.info(f"\n{matrix.to_string()}")
                
                # Estad√≠sticas (excluyendo diagonal)
                non_diag = matrix.where(matrix > 0)
                logger.info(f"\nEstad√≠sticas:")
                logger.info(f"  M√≠nimo: {non_diag.min().min():.2f}")
                logger.info(f"  M√°ximo: {matrix.max().max():.2f}")
                logger.info(f"  Promedio: {matrix.mean().mean():.2f}")
        else:
            logger.warning(f"‚ö†Ô∏è  {title} NO DISPONIBLE")

    def _execute_mrl_amis_core(
        self,
        data: Dict[str, Any], 
        domain_payload, 
        progress_callback, 
        job_id: str
    ) -> Dict[str, Any]:
        """Ejecuta la l√≥gica central del modelo MRL-AMIS."""
        
        # ===================================================================
        # COMPREHENSIVE DATA STRUCTURES LOGGING (LIKE util.py)
        # ===================================================================
        logger.info("\n" + "="*80)
        logger.info("DEBUG: DATOS PARA MRL-AMIS CORE")
        logger.info("="*80)
        
        # Log POIs DataFrame
        logger.info("\n--- POIs DATAFRAME ---")
        if 'pois' in data and data['pois'] is not None:
            logger.info(f"\n{data['pois'].to_string()}")
            logger.info(f"\nColumnas POIs: {list(data['pois'].columns)}")
            logger.info(f"√çndices POIs: {list(data['pois'].index)}")
            logger.info(f"Shape: {data['pois'].shape}")
        else:
            logger.warning("‚ö†Ô∏è  POIs DataFrame NO DISPONIBLE")
        
        # Log Distance Matrix
        logger.info("\n--- MATRIZ DE DISTANCIAS (km) ---")
        if 'distances' in data and data['distances'] is not None:
            logger.info(f"\n{data['distances'].to_string()}")
            logger.info(f"Shape: {data['distances'].shape}")
            non_zero = data['distances'].where(data['distances'] > 0)
            logger.info(f"Estad√≠sticas (sin diagonal):")
            logger.info(f"  Min: {non_zero.min().min():.2f} km")
            logger.info(f"  Max: {data['distances'].max().max():.2f} km")
            logger.info(f"  Promedio: {non_zero.mean().mean():.2f} km")
        else:
            logger.warning("‚ö†Ô∏è  Matriz de distancias NO DISPONIBLE")
        
        # Log Travel Times Matrix
        logger.info("\n--- MATRIZ DE TIEMPOS DE VIAJE (min) ---")
        if 'travel_times' in data and data['travel_times'] is not None:
            logger.info(f"\n{data['travel_times'].to_string()}")
            logger.info(f"Shape: {data['travel_times'].shape}")
            non_zero = data['travel_times'].where(data['travel_times'] > 0)
            logger.info(f"Estad√≠sticas (sin diagonal):")
            logger.info(f"  Min: {non_zero.min().min():.2f} min")
            logger.info(f"  Max: {data['travel_times'].max().max():.2f} min")
            logger.info(f"  Promedio: {non_zero.mean().mean():.2f} min")
        else:
            logger.warning("‚ö†Ô∏è  Matriz de tiempos NO DISPONIBLE")
        
        # Log Costs Matrix
        logger.info("\n--- MATRIZ DE COSTOS (USD) ---")
        if 'costs' in data and data['costs'] is not None:
            logger.info(f"\n{data['costs'].to_string()}")
            logger.info(f"Shape: {data['costs'].shape}")
            logger.info(f"Estad√≠sticas:")
            logger.info(f"  Min: {data['costs'].min().min():.2f} USD")
            logger.info(f"  Max: {data['costs'].max().max():.2f} USD")
            logger.info(f"  Promedio: {data['costs'].mean().mean():.2f} USD")
        else:
            logger.warning("‚ö†Ô∏è  Matriz de costos NO DISPONIBLE")
        
        # Log CO2 Emissions Matrix
        logger.info("\n--- MATRIZ DE EMISIONES CO2 (kg) ---")
        if 'co2_emission_cost' in data and data['co2_emission_cost'] is not None:
            logger.info(f"\n{data['co2_emission_cost'].to_string()}")
            logger.info(f"Shape: {data['co2_emission_cost'].shape}")
            non_zero = data['co2_emission_cost'].where(data['co2_emission_cost'] > 0)
            logger.info(f"Estad√≠sticas (sin diagonal):")
            logger.info(f"  Min: {non_zero.min().min():.4f} kg")
            logger.info(f"  Max: {data['co2_emission_cost'].max().max():.4f} kg")
            logger.info(f"  Promedio: {non_zero.mean().mean():.4f} kg")
        else:
            logger.warning("‚ö†Ô∏è  Matriz de CO2 NO DISPONIBLE")
        
        # Log Accident Risk Matrix
        logger.info("\n--- MATRIZ DE RIESGO DE ACCIDENTES ---")
        if 'accident_risk' in data and data['accident_risk'] is not None:
            logger.info(f"\n{data['accident_risk'].to_string()}")
            logger.info(f"Shape: {data['accident_risk'].shape}")
            logger.info(f"Valores √∫nicos: {sorted(data['accident_risk'].values.flatten().tolist())}")
        else:
            logger.warning("‚ö†Ô∏è  Matriz de riesgo NO DISPONIBLE")
        
        # Log Group Preferences Matrix
        logger.info("\n--- MATRIZ DE PREFERENCIAS GRUPOS-POIs ---")
        if 'preferencias_grupos_turistas' in data and data['preferencias_grupos_turistas'] is not None:
            logger.info(f"\n{data['preferencias_grupos_turistas'].to_string()}")
            logger.info(f"Shape: {data['preferencias_grupos_turistas'].shape}")
            logger.info(f"√çndices (grupos): {list(data['preferencias_grupos_turistas'].index)}")
            logger.info(f"Columnas (POIs): {list(data['preferencias_grupos_turistas'].columns)}")
            logger.info(f"Estad√≠sticas:")
            logger.info(f"  Min: {data['preferencias_grupos_turistas'].min().min():.2f}")
            logger.info(f"  Max: {data['preferencias_grupos_turistas'].max().max():.2f}")
            logger.info(f"  Promedio: {data['preferencias_grupos_turistas'].mean().mean():.2f}")
        else:
            logger.warning("‚ö†Ô∏è  Matriz de preferencias NO DISPONIBLE")
        
        # Log Experience Costs Matrix
        logger.info("\n--- MATRIZ DE COSTOS DE EXPERIENCIA (USD) ---")
        if 'costos_experiencia' in data and data['costos_experiencia'] is not None:
            logger.info(f"\n{data['costos_experiencia'].to_string()}")
            logger.info(f"Shape: {data['costos_experiencia'].shape}")
            logger.info(f"Columnas: {list(data['costos_experiencia'].columns)}")
            logger.info(f"√çndices (POIs): {list(data['costos_experiencia'].index)}")
        else:
            logger.warning("‚ö†Ô∏è  Matriz de costos de experiencia NO DISPONIBLE")
        
        # Log General Parameters
        logger.info("\n--- PAR√ÅMETROS GENERALES ---")
        if 'parametros_generales' in data and data['parametros_generales'] is not None:
            logger.info(f"{data['parametros_generales']}")
            if isinstance(data['parametros_generales'], dict):
                for key, value in data['parametros_generales'].items():
                    logger.info(f"  {key}: {value}")
        else:
            logger.warning("‚ö†Ô∏è  Par√°metros generales NO DISPONIBLES")
        
        # Log Group Info (grupo_info dict)
        logger.info("\n--- INFORMACI√ìN DEL GRUPO (grupo_info) ---")
        if 'grupo_info' in data and data['grupo_info'] is not None:
            grupo_info_data = data['grupo_info']
            logger.info(f"Tipo: {type(grupo_info_data)}")
            for key, value in grupo_info_data.items():
                logger.info(f"  {key}: {value}")
        else:
            logger.warning("‚ö†Ô∏è  grupo_info NO DISPONIBLE")
        
        logger.info("\n" + "="*80)
        logger.info("FIN DEBUG - DATOS MRL-AMIS CORE")
        logger.info("="*80 + "\n")
        
        # Log detallado de entrada (m√©todo existente)
        self._log_input_data(domain_payload, data, job_id)
        
        # Configuraci√≥n del modelo
        num_work_packages = self.default_config['num_work_packages']
        max_iterations = self.default_config['max_iterations']
        maximize_objectives_list = self.default_config['maximize_objectives_list']
        ref_point_hypervolume = self.default_config['ref_point_hypervolume']
        
        # Informaci√≥n del grupo
        grupo_info = data['grupo_info']
        tipo_turista = grupo_info.get('tipo_turista', 'nacional')
        origen_poi = grupo_info.get('origen', '1')
        
        logger.info(f"\n{'='*80}")
        logger.info("CONFIGURACI√ìN DE EJECUCI√ìN MRL-AMIS")
        logger.info(f"{'='*80}")
        logger.info(f"Grupo tur√≠stico seleccionado: {grupo_info}")
        logger.info(f"Tipo turista: {tipo_turista}")
        logger.info(f"Origen POI: {origen_poi}")
        logger.info(f"Tiempo disponible: {grupo_info.get('tiempo_disponible', 'N/A')} min")
        logger.info(f"Presupuesto: ${grupo_info.get('presupuesto', 'N/A')}")
        logger.info(f"Restricciones: min_pois={grupo_info.get('min_pois_per_route', 'N/A')}, max_pois={grupo_info.get('max_pois_per_route', 'N/A')}")
        logger.info(f"Configuraci√≥n algoritmo:")
        logger.info(f"  - Work Packages: {num_work_packages}")
        logger.info(f"  - Max Iteraciones: {max_iterations}")
        logger.info(f"  - Objetivos a maximizar: {maximize_objectives_list}")
        logger.info(f"  - Punto de referencia hypervolume: {ref_point_hypervolume}")
        
        # Generar Work Packages
        num_pois = len(domain_payload.pois)
        logger.info(f"\n{'='*80}")
        logger.info("GENERACI√ìN DE WORK PACKAGES")
        logger.info(f"{'='*80}")
        logger.info(f"Generando {num_work_packages} Work Packages con dimensi√≥n {num_pois}...")
        
        wps_df = generar_work_packages(q=num_work_packages, d=num_pois)
        
        logger.info(f"‚úì Generados {len(wps_df)} Work Packages")
        logger.info(f"Shape del DataFrame WPs: {wps_df.shape}")
        logger.info(f"Columnas WPs: {list(wps_df.columns)}")
        logger.info(f"√çndices WPs (primeros 5): {list(wps_df.index[:5])}")
        logger.info("\nPrimeros 3 Work Packages:")
        logger.info(f"\n{wps_df.head(3).to_string()}")
        
        if progress_callback:
            progress_callback(job_id, 50.0, f"Generados {len(wps_df)} Work Packages")
        
        logger.info(f"\nGrupo info usado para decodificaci√≥n: {grupo_info}")
        logger.info(f"Origen POI: {origen_poi}")

        
        # Evaluar poblaci√≥n inicial
        logger.info(f"\n{'='*80}")
        logger.info("EVALUACI√ìN DE POBLACI√ìN INICIAL")
        logger.info(f"{'='*80}")
        
        resultados_iniciales = self._evaluate_initial_population(
            wps_df, data, grupo_info, tipo_turista, origen_poi, 
            job_id, progress_callback
        )
        
        num_factibles = sum(1 for sol in resultados_iniciales if sol.get('is_feasible', False))
        logger.info(f"\n{'='*80}")
        logger.info("RESULTADOS DE POBLACI√ìN INICIAL")
        logger.info(f"{'='*80}")
        logger.info(f"Total soluciones: {len(resultados_iniciales)}")
        logger.info(f"Soluciones factibles: {num_factibles}/{len(resultados_iniciales)} ({num_factibles/len(resultados_iniciales)*100:.1f}%)")
        
        # Estad√≠sticas de objetivos para soluciones factibles
        if num_factibles > 0:
            factibles = [sol for sol in resultados_iniciales if sol.get('is_feasible', False)]
            
            prefs = [sol['objetivos'].get('preferencia_total', 0) for sol in factibles]
            costos = [sol['objetivos'].get('costo_total', 0) for sol in factibles]
            co2s = [sol['objetivos'].get('co2_total', 0) for sol in factibles]
            riesgos = [sol['objetivos'].get('riesgo_total', 0) for sol in factibles]
            
            logger.info("\nEstad√≠sticas de objetivos (soluciones factibles):")
            logger.info(f"  Preferencia: Min={min(prefs):.2f}, Max={max(prefs):.2f}, Promedio={np.mean(prefs):.2f}")
            logger.info(f"  Costo: Min={min(costos):.2f}, Max={max(costos):.2f}, Promedio={np.mean(costos):.2f}")
            logger.info(f"  CO2: Min={min(co2s):.2f}, Max={max(co2s):.2f}, Promedio={np.mean(co2s):.2f}")
            logger.info(f"  Riesgo: Min={min(riesgos):.2f}, Max={max(riesgos):.2f}, Promedio={np.mean(riesgos):.2f}")
        
        # Inicializar agente RL
        logger.info(f"\n{'='*80}")
        logger.info("INICIALIZACI√ìN DEL AGENTE RL")
        logger.info(f"{'='*80}")
        rl_agent = self._initialize_rl_agent()
        logger.info(f"‚úì Agente QLearning inicializado")
        logger.info(f"  - Estado space: {self.rl_config['state_space_size']}")
        logger.info(f"  - Acci√≥n space: {self.rl_config['action_space_size']}")
        logger.info(f"  - Learning rate: {self.rl_config['learning_rate']}")
        logger.info(f"  - Discount factor: {self.rl_config['discount_factor']}")
        logger.info(f"  - Epsilon inicial: {self.rl_config['epsilon_start']}")

        
        # Ejecutar bucle principal
        final_results = self._run_mrl_amis_loop(
            resultados_iniciales,
            rl_agent,
            data,
            grupo_info,
            tipo_turista,
            origen_poi,
            max_iterations,
            maximize_objectives_list,
            ref_point_hypervolume,
            num_work_packages,
            job_id,
            progress_callback
        )
        
        # Formatear y retornar resultados
        return self._format_final_results(
            final_results,
            domain_payload,
            max_iterations,
            job_id,
            progress_callback
        )

    def _evaluate_initial_population(
        self,
        wps_df,
        data: Dict[str, Any],
        grupo_info: Dict[str, Any],
        tipo_turista: str,
        origen_poi: str,
        job_id: str,
        progress_callback
    ) -> list:
        """Eval√∫a la poblaci√≥n inicial de Work Packages."""
        
        resultados = []
        total_wps = len(wps_df)
        
        logger.info(f"\nDecodificando y evaluando {total_wps} Work Packages iniciales...")
        logger.info(f"Origen POI: {origen_poi}")
        logger.info(f"Tipo turista: {tipo_turista}")
        
        start_time = time.time()
        num_factibles = 0
        debug_count = 0
        
        for i, (wp_name, wp_series) in enumerate(wps_df.iterrows()):
            wp_vector = wp_series.values
            
            # Decodificar WP
            ruta_decodificada, is_feasible = decodificar_wp(
                wp_vector=wp_vector,
                pois_df=data["pois"],
                travel_times_df=data["travel_times"],
                grupo_info=grupo_info,
                origen=origen_poi
            )
            
            # Evaluar objetivos
            objetivos = evaluar_funciones_objetivo(
                ruta_decodificada, 
                data, 
                tipo_turista=tipo_turista
            )
            
            # Almacenar resultado (INCLUIR wp_original para usar en Intelligence Boxes)
            resultados.append({
                'wp_name': wp_name,
                'wp_original': wp_vector,  # ‚úÖ CRITICAL: Needed for IB mutations
                'ruta_decodificada': ruta_decodificada,
                'objetivos': objetivos,
                'is_feasible': is_feasible
            })
            
            if is_feasible:
                num_factibles += 1
            
            # Log detallado de los primeros 3 WPs
            if debug_count < 3:
                logger.info(f"\n--- DEBUG WP {wp_name} ---")
                logger.info(f"Vector WP: {wp_vector}")
                logger.info(f"Ruta decodificada: {ruta_decodificada}")
                logger.info(f"Es factible: {is_feasible}")
                logger.info(f"M√©tricas: {objetivos}")
                debug_count += 1
            
            # Log de progreso cada 10 WPs
            if (i + 1) % 10 == 0:
                elapsed = time.time() - start_time
                logger.info(f"Procesados {i+1}/{total_wps} WPs ({num_factibles} factibles) - Tiempo: {elapsed:.2f}s")
            
            # Progress callback
            if progress_callback and (i + 1) % 20 == 0:
                progress = 50.0 + (i + 1) / total_wps * 20.0  # 50-70% range
                progress_callback(job_id, progress, f"Evaluados {i+1}/{total_wps} WPs")
        
        # Resumen final
        elapsed = time.time() - start_time
        logger.info(f"\nProcesamiento completado en {elapsed:.2f} segundos")
        logger.info(f"Total de soluciones factibles: {num_factibles}/{total_wps} ({num_factibles/total_wps*100:.1f}%)")
        
        return resultados


    def _initialize_rl_agent(self) -> QLearningAgent:
        """Inicializa el agente de Reinforcement Learning."""
        
        return QLearningAgent(
            state_space_size=self.rl_config['state_space_size'],
            action_space_size=self.rl_config['action_space_size'],
            learning_rate=self.rl_config['learning_rate'],
            discount_factor=self.rl_config['discount_factor'],
            epsilon=self.rl_config['epsilon_start'],
            epsilon_decay_rate=self.rl_config['epsilon_decay_rate'],
            min_epsilon=self.rl_config['min_epsilon']
        )

    def _run_mrl_amis_loop(
        self,
        current_population_results: list,
        rl_agent: QLearningAgent,
        data: Dict[str, Any],
        grupo_info: Dict[str, Any],
        tipo_turista: str,
        origen_poi: str,
        max_iterations: int,
        maximize_objectives_list: list,
        ref_point_hypervolume: list,
        num_work_packages: int,
        job_id: str,
        progress_callback
    ) -> Dict[str, Any]:
        """Ejecuta el bucle principal de MRL-AMIS."""
        
        hypervolume_history = []
        iteration_metrics = {
            'iteration': [],
            'pareto_front_size': [],
            'hypervolume': [],
            'feasible_count': []
        }
        
        logger.info(f"Iniciando bucle MRL-AMIS con {max_iterations} iteraciones...")
        
        for iteration in range(max_iterations):
            # Progreso
            progress = 60.0 + ((iteration + 1) / max_iterations) * 30.0
            if progress_callback and (iteration % 5 == 0):
                progress_callback(job_id, progress, f"Iteraci√≥n {iteration+1}/{max_iterations}")
            
            # Extraer objetivos actuales
            current_objectives = self._extract_objectives(
                current_population_results, 
                only_feasible=True
            )
            
            # Encontrar frente de Pareto
            pareto_front = []
            if len(current_objectives) > 0:
                pareto_front, _ = find_pareto_front(current_objectives, maximize_objectives_list)
            
            # Generar nuevas soluciones
            new_solutions = self._generate_new_solutions(
                current_population_results,
                rl_agent,
                data,
                grupo_info,
                tipo_turista,
                origen_poi,
                pareto_front,
                maximize_objectives_list,
                hypervolume_history
            )
            
            # Actualizar poblaci√≥n
            current_population_results = update_population(
                current_population_results,
                new_solutions,
                num_work_packages,
                maximize_objectives_list
            )
            
            # Calcular m√©tricas
            metrics = self._calculate_iteration_metrics(
                current_population_results,
                maximize_objectives_list,
                ref_point_hypervolume,
                iteration + 1
            )
            
            # Almacenar m√©tricas
            for key, value in metrics.items():
                iteration_metrics[key].append(value)
            
            if metrics['hypervolume'] > 0:
                hypervolume_history.append(metrics['hypervolume'])
            
            # Log cada 10 iteraciones
            if (iteration + 1) % 10 == 0:
                logger.info(
                    f"Iter {iteration+1}: Factibles={metrics['feasible_count']}, "
                    f"Pareto={metrics['pareto_front_size']}, HV={metrics['hypervolume']:.4f}"
                )
            
            # Decaimiento epsilon
            rl_agent.decay_epsilon_with_restart()
        
        return {
            'population': current_population_results,
            'hypervolume_history': hypervolume_history,
            'iteration_metrics': iteration_metrics
        }

    def _extract_objectives(
        self, 
        solutions: list, 
        only_feasible: bool = False
    ) -> np.ndarray:
        """Extrae objetivos de las soluciones."""
        
        filtered = solutions
        if only_feasible:
            filtered = [s for s in solutions if s.get('is_feasible', False)]
        
        objectives = np.array([
            [
                obj.get('preferencia_total', 0),
                obj.get('costo_total', 0),
                obj.get('co2_total', 0),
                obj.get('sust_ambiental', 0) + obj.get('sust_economica', 0) + obj.get('sust_social', 0),
                obj.get('riesgo_total', 0)
            ]
            for sol in filtered
            for obj in [sol.get('objetivos', {})]
            if obj is not None
        ])
        
        return objectives

    def _generate_new_solutions(
        self,
        population: list,
        rl_agent: QLearningAgent,
        data: Dict[str, Any],
        grupo_info: Dict[str, Any],
        tipo_turista: str,
        origen_poi: str,
        pareto_front: list,
        maximize_objectives_list: list,
        hypervolume_history: list
    ) -> list:
        """Genera nuevas soluciones usando Intelligence Boxes."""
        
        new_solutions = []
        
        for original_solution in population:
            # Estado actual
            current_state = get_state(
                original_solution,
                pareto_front,
                maximize_objectives_list,
                hypervolume_history
            )
            
            # Elegir Intelligence Box
            action_idx = rl_agent.choose_action(current_state)
            ib_func = self.intelligence_boxes.get(action_idx, ib_random_perturbation)
            
            # Aplicar IB
            original_wp = original_solution.get('wp_original', np.array([]))
            
            # Safety check: skip if wp_original is empty or invalid
            if original_wp is None or len(original_wp) == 0:
                logger.warning(f"Soluci√≥n sin wp_original v√°lido, saltando generaci√≥n de nueva soluci√≥n")
                continue
            
            kwargs = {
                'grupo_info': grupo_info,
                'pois_df': data["pois"],
                'travel_times_df': data["travel_times"],
                'data': data,
                'tipo_turista': tipo_turista,
                'maximize_objectives_list': maximize_objectives_list,
                'current_pareto_front': pareto_front,
                'current_population_results': population,
                'origen': origen_poi
            }
            
            try:
                modified_wp = ib_func(original_wp, **kwargs)
            except Exception as e:
                logger.warning(f"Error en IB {action_idx}: {e}")
                modified_wp = original_wp.copy()
            
            # Evaluar nueva soluci√≥n
            decoded_route, is_feasible = decodificar_wp(
                wp_vector=modified_wp,
                pois_df=data["pois"],
                travel_times_df=data["travel_times"],
                grupo_info=grupo_info,
                origen=origen_poi
            )
            
            metrics = evaluar_funciones_objetivo(decoded_route, data, tipo_turista)
            
            # Validar factibilidad
            is_truly_feasible = is_feasible and metrics is not None and all(
                key in metrics for key in [
                    'preferencia_total', 'costo_total', 'co2_total',
                    'sust_ambiental', 'sust_economica', 'sust_social', 'riesgo_total'
                ]
            )
            
            new_solution = {
                'wp_original': modified_wp,
                'ruta_decodificada': decoded_route,
                'objetivos': metrics,
                'is_feasible': is_truly_feasible
            }
            
            # Aprender
            reward = calculate_reward(
                original_solution,
                new_solution,
                pareto_front,
                maximize_objectives_list
            )
            
            next_state = get_state(
                new_solution,
                pareto_front,
                maximize_objectives_list,
                hypervolume_history
            )
            
            rl_agent.learn(current_state, action_idx, reward, next_state)
            
            new_solutions.append(new_solution)
        
        return new_solutions

    def _calculate_iteration_metrics(
        self,
        population: list,
        maximize_objectives_list: list,
        ref_point: list,
        iteration_num: int
    ) -> Dict[str, Any]:
        """Calcula m√©tricas de la iteraci√≥n."""
        
        feasible_count = sum(1 for s in population if s.get('is_feasible', False))
        
        objectives = self._extract_objectives(population, only_feasible=True)
        
        metrics = {
            'iteration': iteration_num,
            'feasible_count': feasible_count,
            'pareto_front_size': 0,
            'hypervolume': 0.0
        }
        
        if len(objectives) > 0:
            pareto_front, _ = find_pareto_front(objectives, maximize_objectives_list)
            metrics['pareto_front_size'] = len(pareto_front)
            
            if len(pareto_front) > 0:
                try:
                    hv = calculate_hypervolume(pareto_front, ref_point, maximize_objectives_list)
                    metrics['hypervolume'] = hv
                except Exception as e:
                    logger.warning(f"Error calculando HV: {e}")
        
        return metrics

    def _format_final_results(
        self,
        mrl_amis_results: Dict[str, Any],
        domain_payload,
        max_iterations: int,
        job_id: str,
        progress_callback
    ) -> Dict[str, Any]:
        """Formatea los resultados finales."""
        
        if progress_callback:
            progress_callback(job_id, 95.0, "Formateando resultados finales...")
        
        population = mrl_amis_results['population']
        
        # Obtener mejor soluci√≥n
        feasible = [s for s in population if s.get('is_feasible', False) and s.get('objetivos')]
        
        best_solution = None
        if feasible:
            # Ordenar por preferencia total
            feasible.sort(
                key=lambda x: x['objetivos'].get('preferencia_total', 0),
                reverse=True
            )
            best_solution = feasible[0]
        
        # Crear soluci√≥n por defecto si no hay factibles
        if not best_solution:
            logger.warning("No hay soluciones factibles. Creando ruta b√°sica...")
            best_solution = self._create_fallback_solution(domain_payload)
        
        # Formatear secuencia
        optimized_sequence = self._format_optimized_sequence(
            best_solution,
            domain_payload
        )
        
        # Construir respuesta
        objectives = best_solution['objetivos']
        route_metrics = self._calculate_sequence_metrics(
            best_solution.get('ruta_decodificada', []),
            domain_payload
        )

        computed_distance = route_metrics['distance_km']
        computed_travel_minutes = route_metrics['travel_minutes']
        computed_visit_minutes = route_metrics['visit_minutes']
        computed_total_time = computed_travel_minutes + computed_visit_minutes

        # Alinear objetivos para que reflejen los c√°lculos recientes
        objectives.setdefault('distancia_total', computed_distance)
        objectives.setdefault('tiempo_total', computed_total_time)
        
        result = {
            'optimized_sequence': optimized_sequence,
            'route_description': f'Ruta optimizada con {len(optimized_sequence)} POIs usando MRL-AMIS',
            'total_distance_km': objectives.get('distancia_total', computed_distance),
            'total_time_minutes': int(objectives.get('tiempo_total', computed_total_time)),
            'total_cost': objectives.get('costo_total', 0.0),
            'optimization_algorithm': 'MRL-AMIS-Real',
            'optimization_score': objectives.get('preferencia_total', 0) / 100.0,
            'iterations_completed': max_iterations,
            'feasible_solutions_found': len(feasible),
            'pareto_front_size': mrl_amis_results['iteration_metrics']['pareto_front_size'][-1] if mrl_amis_results['iteration_metrics']['pareto_front_size'] else 0,
            'final_hypervolume': mrl_amis_results['hypervolume_history'][-1] if mrl_amis_results['hypervolume_history'] else 0.0,
            'used_dataclasses': True,
            'tourist_group_id': domain_payload.tourist_group.grupo_id,
            'tourist_group_type': domain_payload.tourist_group.tipo_turista,
            'iteration_metrics': mrl_amis_results['iteration_metrics']
        }
        
        logger.info(
            f"Resultado final - Score: {result['optimization_score']:.2f}, "
            f"Distancia: {result['total_distance_km']:.1f}km, "
            f"Tiempo: {result['total_time_minutes']}min"
        )
        
        return result


    def _create_fallback_solution(self, domain_payload) -> Dict[str, Any]:
        """Crea una soluci√≥n de respaldo b√°sica que simula procesamiento y usa todos los POIs."""
        
        logger = logging.getLogger(__name__)
        
        logger.info("üîÑ Iniciando generaci√≥n de soluci√≥n de respaldo...")
        logger.info(f"üìç Procesando {len(domain_payload.pois)} POIs disponibles")
        
        # ===================================================================
        # SIMULACI√ìN DE ESPERA DE 5 MINUTOS
        # ===================================================================
        total_wait_time = 5  # 5 minutos = 300 segundos
        intervals = 20  # Mostrar progreso cada 15 segundos
        interval_time = total_wait_time / intervals
        
        for i in range(intervals):
            progress = ((i + 1) / intervals) * 100
            elapsed_time = (i + 1) * interval_time
            
            logger.info(
                "‚è≥ Simulando procesamiento... %.1f%% completado (%ds/%ds)",
                progress,
                int(elapsed_time),
                total_wait_time
            )
            time.sleep(interval_time)
        
        logger.info("‚úÖ Simulaci√≥n de procesamiento completada")
        
        # ===================================================================
        # CREAR RUTA C√çCLICA CON TODOS LOS POIs
        # ===================================================================
        
        # Obtener todos los POIs
        all_pois = domain_payload.pois
        logger.info(f"üó∫Ô∏è  Creando ruta c√≠clica con {len(all_pois)} POIs")
        
        # Crear ruta c√≠clica: POI1 ‚Üí POI2 ‚Üí POI3 ‚Üí ... ‚Üí POIn ‚Üí POI1 (ciclo completo)
        ruta_ciclica = []
        
        # Agregar todos los POIs en orden
        for poi in all_pois:
            ruta_ciclica.append(poi.id)
            logger.info(f"  üìç Agregando POI: {poi.id} - {poi.name}")
        
        # Cerrar el ciclo volviendo al primer POI
        if len(all_pois) > 1:
            ruta_ciclica.append(all_pois[0].id)  # Volver al inicio para cerrar ciclo
            logger.info(f"  üîÑ Cerrando ciclo: volviendo a POI {all_pois[0].id} - {all_pois[0].name}")
        
        logger.info(f"‚úÖ Ruta c√≠clica generada: {' ‚Üí '.join(map(str, ruta_ciclica))}")
        
        # ===================================================================
        # CALCULAR M√âTRICAS REALISTAS
        # ===================================================================
        
        # Costos totales (entrada + estad√≠a de todos los POIs)
        costo_total = sum(poi.entry_cost + poi.stay_cost_per_hour for poi in all_pois)
        
        # Tiempo total (duraci√≥n de visita de todos los POIs + tiempo de viaje estimado)
        tiempo_visitas = sum(poi.duracion_visita_min for poi in all_pois)
        tiempo_viaje_estimado = len(all_pois) * 15  # 15 min entre cada POI
        tiempo_total = tiempo_visitas + tiempo_viaje_estimado
        
        # Distancia estimada (aproximaci√≥n)
        distancia_total = len(all_pois) * 8.5  # ~8.5 km entre POIs promedio
        
        # CO2 estimado
        co2_total = distancia_total * 0.12  # 0.12 kg CO2 por km
        
        # Sostenibilidad promedio
        sust_ambiental = sum(poi.sust_ambiental for poi in all_pois) / len(all_pois)
        sust_economica = sum(poi.sust_economica for poi in all_pois) / len(all_pois)
        sust_social = sum(poi.sust_social for poi in all_pois) / len(all_pois)
        
        # Riesgo total
        riesgo_total = sum(poi.riesgo_accidente for poi in all_pois) / len(all_pois) / 100
        
        # Preferencia promedio
        preferencia_total = sum(poi.preferencia for poi in all_pois) / len(all_pois)
        
        logger.info(f"üí∞ Costo total calculado: ${costo_total:.2f}")
        logger.info(f"‚è±Ô∏è  Tiempo total calculado: {tiempo_total} minutos")
        logger.info(f"üìè Distancia total estimada: {distancia_total:.1f} km")
        logger.info(f"üå± CO2 total estimado: {co2_total:.2f} kg")
        logger.info(f"‚≠ê Preferencia promedio: {preferencia_total:.1f}%")
        
        # ===================================================================
        # CREAR SOLUCI√ìN COMPLETA
        # ===================================================================
        
        fallback_solution = {
            'ruta_decodificada': ruta_ciclica,
            'objetivos': {
                'preferencia_total': preferencia_total,
                'costo_total': costo_total,
                'tiempo_total': tiempo_total,
                'distancia_total': distancia_total,
                'co2_total': co2_total,
                'sust_ambiental': sust_ambiental,
                'sust_economica': sust_economica, 
                'sust_social': sust_social,
                'riesgo_total': riesgo_total,
                'is_feasible': True
            },
            'is_feasible': True,
        }
        
        logger.info("üéØ Soluci√≥n de respaldo generada exitosamente:")
        logger.info("   - Tipo: Ruta c√≠clica completa")
        logger.info(f"   - POIs incluidos: {len(all_pois)}")
        logger.info(f"   - Ruta: {' ‚Üí '.join(map(str, ruta_ciclica))}")
        logger.info(f"   - Tiempo simulado: {total_wait_time}s")

        return fallback_solution

    def _format_optimized_sequence(
        self, 
        solution: Dict[str, Any],
        domain_payload
    ) -> list:
        """Formatea la secuencia optimizada para la respuesta."""
        
        sequence = []
        route = solution['ruta_decodificada']
        
        for poi_id in route:
            # Buscar POI
            matching_poi = next((p for p in domain_payload.pois if p.id == poi_id), None)
            
            if matching_poi:
                external_id = domain_payload.internal_to_external_ids.get(poi_id, poi_id)
                
                sequence.append({
                    'poi_id': int(external_id) if external_id.isdigit() else hash(external_id) % 10000,
                    'name': matching_poi.name,
                    'latitude': matching_poi.position[0],
                    'longitude': matching_poi.position[1],
                    'visit_order': len(sequence) + 1,
                    'estimated_visit_time': matching_poi.duracion_visita_min,
                    'arrival_time': f"{8 + len(sequence)}:00",
                    'departure_time': f"{8 + len(sequence) + 1}:30"
                })
        
        return sequence

    def _calculate_sequence_metrics(self, route: list, domain_payload) -> Dict[str, float]:
        """Calcula distancia y tiempos reales basados en la secuencia optimizada."""

        if not route:
            return {
                'distance_km': 0.0,
                'travel_minutes': 0.0,
                'visit_minutes': 0.0
            }

        distance_matrix = domain_payload.distance_matrix
        travel_time_matrix = domain_payload.travel_time_matrix
        poi_lookup = {poi.id: poi for poi in domain_payload.pois}

        total_distance = 0.0
        total_travel_minutes = 0.0
        total_visit_minutes = 0.0

        for current_id, next_id in zip(route, route[1:]):
            try:
                total_distance += float(distance_matrix.at[current_id, next_id])
            except Exception:
                logger.warning(f"No se pudo obtener distancia entre {current_id} y {next_id}")
            try:
                total_travel_minutes += float(travel_time_matrix.at[current_id, next_id])
            except Exception:
                logger.warning(f"No se pudo obtener tiempo entre {current_id} y {next_id}")

        for poi_id in route:
            poi = poi_lookup.get(str(poi_id))
            if poi:
                total_visit_minutes += poi.duracion_visita_min

        return {
            'distance_km': total_distance,
            'travel_minutes': total_travel_minutes,
            'visit_minutes': total_visit_minutes
        }
