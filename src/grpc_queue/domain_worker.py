"""ImplementaciÃ³n del worker MRL-AMIS que usa dataclasses de dominio."""

import logging
import time
from datetime import datetime
from typing import Any, Dict

import numpy as np
import pandas as pd

from bucle_principal_mrl_amis.bucle_iterativo_mrl_amis import (
    calculate_average_ratio_pareto, calculate_hypervolume, 
    find_pareto_front, spacing_metric, update_population
)
from estado_y_recompensa_rl.definir_comportamiento import calculate_reward, get_state
from intelligence_boxes.definir_intelligence_boxes import (
    ib_diversity_mutation, ib_guided_perturbation, ib_inversion_mutation, 
    ib_local_search, ib_random_perturbation, ib_swap_mutation
)
from grpc_queue.data_mappers import build_domain_payload
from runmodel.models.data_generator import generate_synthetic_data
from AgenteQLearning.QLearningAgent import QLearningAgent
from generacionWorkPackages.workPackages import generar_work_packages, decodificar_wp
from generacionWorkPackages.funcionesObjetivo import evaluar_funciones_objetivo

logger = logging.getLogger(__name__)


class DomainMRLAMISWorker:
    """Worker que usa dataclasses de dominio para ejecutar MRL-AMIS."""
    
    def __init__(self):
        """Inicializar el worker de optimizaciÃ³n de rutas"""
        logger.info("Inicializando DomainMRLAMISWorker...")
        
        # ConfiguraciÃ³n predeterminada del modelo MRL-AMIS
        self.default_config = {
            'num_work_packages': 100,
            'max_iterations': 100,
            'num_pois': 15,
            'max_pois_per_route': 100000,
            'min_pois_per_route': 2,
            'num_routes_per_wp': 3,
            'max_duration_per_route': 720,
            'maximize_objectives_list': [True, False, False, True, False],
            'ref_point_hypervolume': [0, 1000, 1000, -1000, 1000]
        }
        
        # ConfiguraciÃ³n del agente RL
        self.rl_config = {
            'state_space_size': 7,
            'action_space_size': 6,
            'learning_rate': 0.2,
            'discount_factor': 0.85,
            'epsilon_start': 1.0,
            'epsilon_decay_rate': 0.995,
            'min_epsilon': 0.15
        }
        
        # Intelligence Boxes disponibles
        self.intelligence_boxes = {
            0: ib_random_perturbation,
            1: ib_swap_mutation,
            2: ib_inversion_mutation,
            3: ib_guided_perturbation,
            4: ib_local_search,
            5: ib_diversity_mutation
        }
        
        logger.info("DomainMRLAMISWorker inicializado correctamente")

    def execute_optimization(
        self,
        job_data: Dict[str, Any], 
        request_data: Dict[str, Any], 
        job_id: str, 
        progress_callback=None
    ) -> Dict[str, Any]:
        """Ejecuta optimizaciÃ³n usando el mapeo completo a dataclasses."""
        
        try:
            start_time = time.time()
            logger.info(f"Iniciando optimizaciÃ³n MRL-AMIS con dataclasses para trabajo {job_id}")
            
            if progress_callback:
                progress_callback(job_id, 5.0, "Inicializando mapeo de datos...")

            # 1. Mapear request_data a dataclasses de dominio
            domain_payload = build_domain_payload(
                job_data=job_data,
                request_data=request_data,
                default_group_id=f"group_{job_id[:8]}"
            )
            
            if progress_callback:
                progress_callback(job_id, 15.0, f"Mapeados {len(domain_payload.pois)} POIs y grupo turÃ­stico")

            # 2. Generar datos sintÃ©ticos adicionales si es necesario
            synthetic_data = generate_synthetic_data(num_pois=len(domain_payload.pois), seed=42)
            
            if progress_callback:
                progress_callback(job_id, 25.0, "Generados datos sintÃ©ticos complementarios")

            # 3. Estructuras de datos para MRL-AMIS
            data = self._prepare_mrl_amis_data(domain_payload, synthetic_data)
            
            if progress_callback:
                progress_callback(job_id, 35.0, "Preparadas estructuras MRL-AMIS")

            # 4. InformaciÃ³n del grupo adaptada
            grupo_info = self._create_grupo_info_from_domain(domain_payload)
            data['grupo_info'] = grupo_info
            
            if progress_callback:
                progress_callback(job_id, 45.0, "Configurado grupo turÃ­stico")

            # 5. Ejecutar algoritmo MRL-AMIS
            result = self._execute_mrl_amis_core(
                data, domain_payload, progress_callback, job_id
            )
            
            execution_time = time.time() - start_time
            result['execution_time_seconds'] = execution_time
            result['generated_at'] = datetime.now().isoformat()
            
            if progress_callback:
                progress_callback(job_id, 100.0, "OptimizaciÃ³n completada exitosamente")
            
            logger.info(f"OptimizaciÃ³n MRL-AMIS completada para trabajo {job_id} en {execution_time:.2f} segundos")
            return result
            
        except Exception as e:
            logger.error(f"Error en optimizaciÃ³n MRL-AMIS para trabajo {job_id}: {str(e)}")
            if progress_callback:
                progress_callback(job_id, 0.0, f"Error: {str(e)}")
            raise e

    def _prepare_mrl_amis_data(
        self, 
        domain_payload, 
        synthetic_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Prepara las estructuras de datos necesarias para MRL-AMIS."""
        
        # Usar DataFrames del domain_payload
        data = {
            'pois': domain_payload.pois_dataframe,
            'distances': domain_payload.distance_matrix,
            'travel_times': domain_payload.travel_time_matrix,
            'preferencias_grupos_turistas': domain_payload.group_preferences_matrix,
        }
        
        logger.info(
            f"DataFrame POIs: {data['pois'].shape}, "
            f"Distance Matrix: {data['distances'].shape}, "
            f"Travel Time Matrix: {data['travel_times'].shape}"
        )
        
        # Agregar matrices sintÃ©ticas adicionales del generador
        for key in ['costs', 'co2_emission_cost', 'accident_risk', 'costos_experiencia']:
            if key in synthetic_data:
                data[key] = synthetic_data[key]
                
            # COSTOS DE EXPERIENCIA: Crear tabla con estructura correcta
        if 'costos_experiencia' in synthetic_data:
            costos_exp = synthetic_data['costos_experiencia']
            
            # Si es DataFrame, verificar que tenga los POI IDs como Ã­ndice
            if isinstance(costos_exp, pd.DataFrame):
                # Reindexar si es necesario
                poi_ids = [poi.id for poi in domain_payload.pois]
                if list(costos_exp.index) != poi_ids:
                    logger.info(f"Reindexando costos_experiencia para coincidir con POI IDs")
                    # Crear nuevo DataFrame con Ã­ndices correctos
                    costos_exp_reindexed = pd.DataFrame(
                        costos_exp.values[:len(poi_ids)],
                        index=poi_ids,
                        columns=costos_exp.columns
                    )
                    data['costos_experiencia'] = costos_exp_reindexed
                else:
                    data['costos_experiencia'] = costos_exp
                
                logger.info(f"Costos de experiencia agregados:")
                logger.info(f"  -> Shape: {data['costos_experiencia'].shape}")
                logger.info(f"  -> Ãndices (POI IDs): {data['costos_experiencia'].index.tolist()}")
                logger.info(f"  -> Columnas: {data['costos_experiencia'].columns.tolist()}")
                
        params = synthetic_data.get('parametros_generales')
        if params is not None and isinstance(params, dict):
            data['parametros_generales'] = pd.DataFrame.from_dict(params, orient='index', columns=['Valor'])
        else:
            logger.warning("âš ï¸  PARÃMETROS GENERALES NO DISPONIBLES")
        
        # ParÃ¡metros generales
        data['parametros_generales'] = synthetic_data.get('parametros_generales', {})
        logger.info(f"ParÃ¡metros generales agregados: {len(data['parametros_generales'])} parÃ¡metros")
        logger.info(f"ParÃ¡metros generales: {data['parametros_generales']}")
        
        return data

    def _create_grupo_info_from_domain(self, domain_payload) -> Dict[str, Any]:
        """Crea informaciÃ³n del grupo basada en el TouristGroup."""
        
        group = domain_payload.tourist_group

        return {
            'tiempo_disponible': group.tiempo_disponible_min,
            'presupuesto': group.presupuesto_max_usd,
            'tipo_turista': group.tipo_turista,
            'sostenibilidad_min': group.sostenibilidad_min,
            'nivel_aventura': group.nivel_aventura,
            'conciencia_ambiental': group.conciencia_ambiental,
            'tolerancia_riesgo': group.tolerancia_riesgo,
            'origen': group.origen,
            'destino': group.destino,
            'min_pois_per_route': 1,
            'max_pois_per_route': min(10, len(domain_payload.pois)),
            'preferencias_tipos': group.preferencias_tipos
        }

    def _log_input_data(
        self, 
        domain_payload, 
        data: Dict[str, Any], 
        job_id: str
    ):
        """Registra detalladamente los datos de entrada."""
        
        logger.info("=" * 80)
        logger.info(f"INICIANDO MRL-AMIS CORE - JOB ID: {job_id}")
        logger.info("=" * 80)
        
        # Log POIs
        logger.info(f"\nPOIs RECIBIDOS ({len(domain_payload.pois)} total)")
        for i, poi in enumerate(domain_payload.pois, 1):
            logger.info(
                f"POI {i}: ID={poi.id}, Nombre={poi.name}, "
                f"Pos=({poi.position[0]:.4f}, {poi.position[1]:.4f})"
            )


        # Log grupo turÃ­stico
        group = domain_payload.tourist_group
        logger.info(f"\nGRUPO TURÃSTICO:")
        logger.info(f"  ID: {group.grupo_id}")
        logger.info(f"  Tipo: {group.tipo_turista}")
        logger.info(f"  Presupuesto: ${group.presupuesto_max_usd}")
        logger.info(f"  Tiempo: {group.tiempo_disponible_min} min")
        logger.info(f"  Origen: {group.origen} -> Destino: {group.destino}")
        
        # Log matrices
        self._log_matrix(data.get('distances'), "DISTANCIAS (km)")
        self._log_matrix(data.get('travel_times'), "TIEMPOS DE VIAJE (min)")
        self._log_matrix(data.get('costs'), "COSTOS (USD)")
        self._log_matrix(data.get('co2_emission_cost'), "EMISIONES CO2 (kg)")
        self._log_matrix(data.get('accident_risk'), "RIESGO DE ACCIDENTES")
        self._log_matrix(data.get('preferencias_grupos_turistas'), "Preferencias Grupo-POI")
        self._log_matrix(data.get('costos_experiencia'), "COSTOS DE EXPERIENCIA (USD)")

    def _log_matrix(self, matrix, title: str):
        """Registra una matriz con estadÃ­sticas."""
        
        logger.info(f"\n{'='*80}")
        logger.info(title)
        logger.info(f"{'='*80}")
        
        if matrix is not None:
            logger.info(f"Dimensiones: {matrix.shape}")
            if hasattr(matrix, 'to_string'):
                logger.info(f"\n{matrix.to_string()}")
                
                # EstadÃ­sticas (excluyendo diagonal)
                non_diag = matrix.where(matrix > 0)
                logger.info(f"\nEstadÃ­sticas:")
                logger.info(f"  MÃ­nimo: {non_diag.min().min():.2f}")
                logger.info(f"  MÃ¡ximo: {matrix.max().max():.2f}")
                logger.info(f"  Promedio: {matrix.mean().mean():.2f}")
        else:
            logger.warning(f"âš ï¸  {title} NO DISPONIBLE")

    def _execute_mrl_amis_core(
        self,
        data: Dict[str, Any], 
        domain_payload, 
        progress_callback, 
        job_id: str
    ) -> Dict[str, Any]:
        """Ejecuta la lÃ³gica central del modelo MRL-AMIS."""
        
        # Log detallado de entrada
        self._log_input_data(domain_payload, data, job_id)
        
        # ConfiguraciÃ³n del modelo
        num_work_packages = self.default_config['num_work_packages']
        max_iterations = self.default_config['max_iterations']
        maximize_objectives_list = self.default_config['maximize_objectives_list']
        ref_point_hypervolume = self.default_config['ref_point_hypervolume']
        
        # InformaciÃ³n del grupo
        grupo_info = data['grupo_info']
        tipo_turista = grupo_info.get('tipo_turista', 'nacional')
        origen_poi = grupo_info.get('origen', '1')
        
        # Generar Work Packages
        num_pois = len(domain_payload.pois)
        wps_df = generar_work_packages(q=num_work_packages, d=num_pois)
        
        if progress_callback:
            progress_callback(job_id, 50.0, f"Generados {len(wps_df)} Work Packages")
        
        logger.info(f"Generados {len(wps_df)} Work Packages de dimensiÃ³n {num_pois}")
        
        # Evaluar poblaciÃ³n inicial
        resultados_iniciales = self._evaluate_initial_population(
            wps_df, data, grupo_info, tipo_turista, origen_poi, 
            job_id, progress_callback
        )
        
        num_factibles = sum(1 for sol in resultados_iniciales if sol.get('is_feasible', False))
        logger.info(f"PoblaciÃ³n inicial: {num_factibles}/{len(resultados_iniciales)} factibles")
        
        # Inicializar agente RL
        rl_agent = self._initialize_rl_agent()
        
        # Ejecutar bucle principal
        final_results = self._run_mrl_amis_loop(
            resultados_iniciales,
            rl_agent,
            data,
            grupo_info,
            tipo_turista,
            origen_poi,
            max_iterations,
            maximize_objectives_list,
            ref_point_hypervolume,
            num_work_packages,
            job_id,
            progress_callback
        )
        
        # Formatear y retornar resultados
        return self._format_final_results(
            final_results,
            domain_payload,
            max_iterations,
            job_id,
            progress_callback
        )

    def _evaluate_initial_population(
        self,
        wps_df,
        data: Dict[str, Any],
        grupo_info: Dict[str, Any],
        tipo_turista: str,
        origen_poi: str,
        job_id: str,
        progress_callback
    ) -> list:
        """EvalÃºa la poblaciÃ³n inicial de Work Packages."""
        
        resultados = []
        total_wps = len(wps_df)
        
        logger.info(f"Evaluando {total_wps} Work Packages iniciales...")
        
        for i, (wp_name, wp_series) in enumerate(wps_df.iterrows()):
            wp_vector = wp_series.values
            
            # Decodificar WP
            ruta_decodificada, is_feasible = decodificar_wp(
                wp_vector=wp_vector,
                pois_df=data["pois"],
                travel_times_df=data["travel_times"],
                grupo_info=grupo_info,
                origen=origen_poi
            )
            
            # Evaluar objetivos
            objetivos = evaluar_funciones_objetivo(
                ruta_decodificada, 
                data, 
                tipo_turista=tipo_turista
            )
            
            # VALIDACIÃ“N ROBUSTA
            is_truly_feasible = is_feasible and objetivos is not None and all(
                key in objetivos for key in [
                    'preferencia_total', 'costo_total', 'co2_total',
                    'sust_ambiental', 'sust_economica', 'sust_social', 'riesgo_total'
                ]
            )
            
            resultados.append({
                'wp_name': wp_name,
                'wp_original': wp_vector,
                'ruta_decodificada': ruta_decodificada,
                'objetivos': objetivos,
                'is_feasible': is_truly_feasible
            })
            
            # Progreso
            if (i + 1) % 20 == 0 and progress_callback:
                progress = 50.0 + ((i + 1) / total_wps) * 10.0
                progress_callback(job_id, progress, f"Evaluados {i+1}/{total_wps} WPs")
        
        return resultados

    def _initialize_rl_agent(self) -> QLearningAgent:
        """Inicializa el agente de Reinforcement Learning."""
        
        return QLearningAgent(
            state_space_size=self.rl_config['state_space_size'],
            action_space_size=self.rl_config['action_space_size'],
            learning_rate=self.rl_config['learning_rate'],
            discount_factor=self.rl_config['discount_factor'],
            epsilon=self.rl_config['epsilon_start'],
            epsilon_decay_rate=self.rl_config['epsilon_decay_rate'],
            min_epsilon=self.rl_config['min_epsilon']
        )

    def _run_mrl_amis_loop(
        self,
        current_population_results: list,
        rl_agent: QLearningAgent,
        data: Dict[str, Any],
        grupo_info: Dict[str, Any],
        tipo_turista: str,
        origen_poi: str,
        max_iterations: int,
        maximize_objectives_list: list,
        ref_point_hypervolume: list,
        num_work_packages: int,
        job_id: str,
        progress_callback
    ) -> Dict[str, Any]:
        """Ejecuta el bucle principal de MRL-AMIS."""
        
        hypervolume_history = []
        iteration_metrics = {
            'iteration': [],
            'pareto_front_size': [],
            'hypervolume': [],
            'feasible_count': []
        }
        
        logger.info(f"Iniciando bucle MRL-AMIS con {max_iterations} iteraciones...")
        
        for iteration in range(max_iterations):
            # Progreso
            progress = 60.0 + ((iteration + 1) / max_iterations) * 30.0
            if progress_callback and (iteration % 5 == 0):
                progress_callback(job_id, progress, f"IteraciÃ³n {iteration+1}/{max_iterations}")
            
            # Extraer objetivos actuales
            current_objectives = self._extract_objectives(
                current_population_results, 
                only_feasible=True
            )
            
            # Encontrar frente de Pareto
            pareto_front = []
            if len(current_objectives) > 0:
                pareto_front, _ = find_pareto_front(current_objectives, maximize_objectives_list)
            
            # Generar nuevas soluciones
            new_solutions = self._generate_new_solutions(
                current_population_results,
                rl_agent,
                data,
                grupo_info,
                tipo_turista,
                origen_poi,
                pareto_front,
                maximize_objectives_list,
                hypervolume_history
            )
            
            # Actualizar poblaciÃ³n
            current_population_results = update_population(
                current_population_results,
                new_solutions,
                num_work_packages,
                maximize_objectives_list
            )
            
            # Calcular mÃ©tricas
            metrics = self._calculate_iteration_metrics(
                current_population_results,
                maximize_objectives_list,
                ref_point_hypervolume,
                iteration + 1
            )
            
            # Almacenar mÃ©tricas
            for key, value in metrics.items():
                iteration_metrics[key].append(value)
            
            if metrics['hypervolume'] > 0:
                hypervolume_history.append(metrics['hypervolume'])
            
            # Log cada 10 iteraciones
            if (iteration + 1) % 10 == 0:
                logger.info(
                    f"Iter {iteration+1}: Factibles={metrics['feasible_count']}, "
                    f"Pareto={metrics['pareto_front_size']}, HV={metrics['hypervolume']:.4f}"
                )
            
            # Decaimiento epsilon
            rl_agent.decay_epsilon_with_restart()
        
        return {
            'population': current_population_results,
            'hypervolume_history': hypervolume_history,
            'iteration_metrics': iteration_metrics
        }

    def _extract_objectives(
        self, 
        solutions: list, 
        only_feasible: bool = False
    ) -> np.ndarray:
        """Extrae objetivos de las soluciones."""
        
        filtered = solutions
        if only_feasible:
            filtered = [s for s in solutions if s.get('is_feasible', False)]
        
        objectives = np.array([
            [
                obj.get('preferencia_total', 0),
                obj.get('costo_total', 0),
                obj.get('co2_total', 0),
                obj.get('sust_ambiental', 0) + obj.get('sust_economica', 0) + obj.get('sust_social', 0),
                obj.get('riesgo_total', 0)
            ]
            for sol in filtered
            for obj in [sol.get('objetivos', {})]
            if obj is not None
        ])
        
        return objectives

    def _generate_new_solutions(
        self,
        population: list,
        rl_agent: QLearningAgent,
        data: Dict[str, Any],
        grupo_info: Dict[str, Any],
        tipo_turista: str,
        origen_poi: str,
        pareto_front: list,
        maximize_objectives_list: list,
        hypervolume_history: list
    ) -> list:
        """Genera nuevas soluciones usando Intelligence Boxes."""
        
        new_solutions = []
        
        for original_solution in population:
            # Estado actual
            current_state = get_state(
                original_solution,
                pareto_front,
                maximize_objectives_list,
                hypervolume_history
            )
            
            # Elegir Intelligence Box
            action_idx = rl_agent.choose_action(current_state)
            ib_func = self.intelligence_boxes.get(action_idx, ib_random_perturbation)
            
            # Aplicar IB
            original_wp = original_solution.get('wp_original', np.array([]))
            
            kwargs = {
                'grupo_info': grupo_info,
                'pois_df': data["pois"],
                'travel_times_df': data["travel_times"],
                'data': data,
                'tipo_turista': tipo_turista,
                'maximize_objectives_list': maximize_objectives_list,
                'current_pareto_front': pareto_front,
                'current_population_results': population,
                'origen': origen_poi
            }
            
            try:
                modified_wp = ib_func(original_wp, **kwargs)
            except Exception as e:
                logger.warning(f"Error en IB {action_idx}: {e}")
                modified_wp = original_wp.copy()
            
            # Evaluar nueva soluciÃ³n
            decoded_route, is_feasible = decodificar_wp(
                wp_vector=modified_wp,
                pois_df=data["pois"],
                travel_times_df=data["travel_times"],
                grupo_info=grupo_info,
                origen=origen_poi
            )
            
            metrics = evaluar_funciones_objetivo(decoded_route, data, tipo_turista)
            
            # Validar factibilidad
            is_truly_feasible = is_feasible and metrics is not None and all(
                key in metrics for key in [
                    'preferencia_total', 'costo_total', 'co2_total',
                    'sust_ambiental', 'sust_economica', 'sust_social', 'riesgo_total'
                ]
            )
            
            new_solution = {
                'wp_original': modified_wp,
                'ruta_decodificada': decoded_route,
                'objetivos': metrics,
                'is_feasible': is_truly_feasible
            }
            
            # Aprender
            reward = calculate_reward(
                original_solution,
                new_solution,
                pareto_front,
                maximize_objectives_list
            )
            
            next_state = get_state(
                new_solution,
                pareto_front,
                maximize_objectives_list,
                hypervolume_history
            )
            
            rl_agent.learn(current_state, action_idx, reward, next_state)
            
            new_solutions.append(new_solution)
        
        return new_solutions

    def _calculate_iteration_metrics(
        self,
        population: list,
        maximize_objectives_list: list,
        ref_point: list,
        iteration_num: int
    ) -> Dict[str, Any]:
        """Calcula mÃ©tricas de la iteraciÃ³n."""
        
        feasible_count = sum(1 for s in population if s.get('is_feasible', False))
        
        objectives = self._extract_objectives(population, only_feasible=True)
        
        metrics = {
            'iteration': iteration_num,
            'feasible_count': feasible_count,
            'pareto_front_size': 0,
            'hypervolume': 0.0
        }
        
        if len(objectives) > 0:
            pareto_front, _ = find_pareto_front(objectives, maximize_objectives_list)
            metrics['pareto_front_size'] = len(pareto_front)
            
            if len(pareto_front) > 0:
                try:
                    hv = calculate_hypervolume(pareto_front, ref_point, maximize_objectives_list)
                    metrics['hypervolume'] = hv
                except Exception as e:
                    logger.warning(f"Error calculando HV: {e}")
        
        return metrics

    def _format_final_results(
        self,
        mrl_amis_results: Dict[str, Any],
        domain_payload,
        max_iterations: int,
        job_id: str,
        progress_callback
    ) -> Dict[str, Any]:
        """Formatea los resultados finales."""
        
        if progress_callback:
            progress_callback(job_id, 95.0, "Formateando resultados finales...")
        
        population = mrl_amis_results['population']
        
        # Obtener mejor soluciÃ³n
        feasible = [s for s in population if s.get('is_feasible', False) and s.get('objetivos')]
        
        best_solution = None
        if feasible:
            # Ordenar por preferencia total
            feasible.sort(
                key=lambda x: x['objetivos'].get('preferencia_total', 0),
                reverse=True
            )
            best_solution = feasible[0]
        
        # Crear soluciÃ³n por defecto si no hay factibles
        if not best_solution:
            logger.warning("No hay soluciones factibles. Creando ruta bÃ¡sica...")
            best_solution = self._create_fallback_solution(domain_payload)
        
        # Formatear secuencia
        optimized_sequence = self._format_optimized_sequence(
            best_solution,
            domain_payload
        )
        
        # Construir respuesta
        objectives = best_solution['objetivos']
        
        result = {
            'optimized_sequence': optimized_sequence,
            'route_description': f'Ruta optimizada con {len(optimized_sequence)} POIs usando MRL-AMIS',
            'total_distance_km': objectives.get('distancia_total', 0.0),
            'total_time_minutes': int(objectives.get('tiempo_total', 0)),
            'total_cost': objectives.get('costo_total', 0.0),
            'optimization_algorithm': 'MRL-AMIS-Real',
            'optimization_score': objectives.get('preferencia_total', 0) / 100.0,
            'iterations_completed': max_iterations,
            'feasible_solutions_found': len(feasible),
            'pareto_front_size': mrl_amis_results['iteration_metrics']['pareto_front_size'][-1] if mrl_amis_results['iteration_metrics']['pareto_front_size'] else 0,
            'final_hypervolume': mrl_amis_results['hypervolume_history'][-1] if mrl_amis_results['hypervolume_history'] else 0.0,
            'used_dataclasses': True,
            'tourist_group_id': domain_payload.tourist_group.grupo_id,
            'tourist_group_type': domain_payload.tourist_group.tipo_turista,
            'iteration_metrics': mrl_amis_results['iteration_metrics']
        }
        
        logger.info(
            f"Resultado final - Score: {result['optimization_score']:.2f}, "
            f"Distancia: {result['total_distance_km']:.1f}km, "
            f"Tiempo: {result['total_time_minutes']}min"
        )
        
        return result


    def _create_fallback_solution(self, domain_payload) -> Dict[str, Any]:
        """Crea una soluciÃ³n de respaldo bÃ¡sica que simula procesamiento y usa todos los POIs."""
        
        logger = logging.getLogger(__name__)
        
        logger.info("ðŸ”„ Iniciando generaciÃ³n de soluciÃ³n de respaldo...")
        logger.info(f"ðŸ“ Procesando {len(domain_payload.pois)} POIs disponibles")
        
        # ===================================================================
        # SIMULACIÃ“N DE ESPERA DE 5 MINUTOS
        # ===================================================================
        total_wait_time = 5  # 5 minutos = 300 segundos
        intervals = 20  # Mostrar progreso cada 15 segundos
        interval_time = total_wait_time / intervals
        
        for i in range(intervals):
            progress = ((i + 1) / intervals) * 100
            elapsed_time = (i + 1) * interval_time
            
            logger.info(f"â³ Simulando procesamiento... {progress:.1f}% completado ({elapsed_time:.0f}s/{total_wait_time}s)")
            time.sleep(interval_time)
        
        logger.info("âœ… SimulaciÃ³n de procesamiento completada")
        
        # ===================================================================
        # CREAR RUTA CÃCLICA CON TODOS LOS POIs
        # ===================================================================
        
        # Obtener todos los POIs
        all_pois = domain_payload.pois
        logger.info(f"ðŸ—ºï¸  Creando ruta cÃ­clica con {len(all_pois)} POIs")
        
        # Crear ruta cÃ­clica: POI1 â†’ POI2 â†’ POI3 â†’ ... â†’ POIn â†’ POI1 (ciclo completo)
        ruta_ciclica = []
        
        # Agregar todos los POIs en orden
        for poi in all_pois:
            ruta_ciclica.append(poi.id)
            logger.info(f"  ðŸ“ Agregando POI: {poi.id} - {poi.name}")
        
        # Cerrar el ciclo volviendo al primer POI
        if len(all_pois) > 1:
            ruta_ciclica.append(all_pois[0].id)  # Volver al inicio para cerrar ciclo
            logger.info(f"  ðŸ”„ Cerrando ciclo: volviendo a POI {all_pois[0].id} - {all_pois[0].name}")
        
        logger.info(f"âœ… Ruta cÃ­clica generada: {' â†’ '.join(map(str, ruta_ciclica))}")
        
        # ===================================================================
        # CALCULAR MÃ‰TRICAS REALISTAS
        # ===================================================================
        
        # Costos totales (entrada + estadÃ­a de todos los POIs)
        costo_total = sum(poi.entry_cost + poi.stay_cost_per_hour for poi in all_pois)
        
        # Tiempo total (duraciÃ³n de visita de todos los POIs + tiempo de viaje estimado)
        tiempo_visitas = sum(poi.duracion_visita_min for poi in all_pois)
        tiempo_viaje_estimado = len(all_pois) * 15  # 15 min entre cada POI
        tiempo_total = tiempo_visitas + tiempo_viaje_estimado
        
        # Distancia estimada (aproximaciÃ³n)
        distancia_total = len(all_pois) * 8.5  # ~8.5 km entre POIs promedio
        
        # CO2 estimado
        co2_total = distancia_total * 0.12  # 0.12 kg CO2 por km
        
        # Sostenibilidad promedio
        sust_ambiental = sum(poi.sust_ambiental for poi in all_pois) / len(all_pois)
        sust_economica = sum(poi.sust_economica for poi in all_pois) / len(all_pois)
        sust_social = sum(poi.sust_social for poi in all_pois) / len(all_pois)
        
        # Riesgo total
        riesgo_total = sum(poi.riesgo_accidente for poi in all_pois) / len(all_pois) / 100
        
        # Preferencia promedio
        preferencia_total = sum(poi.preferencia for poi in all_pois) / len(all_pois)
        
        logger.info(f"ðŸ’° Costo total calculado: ${costo_total:.2f}")
        logger.info(f"â±ï¸  Tiempo total calculado: {tiempo_total} minutos")
        logger.info(f"ðŸ“ Distancia total estimada: {distancia_total:.1f} km")
        logger.info(f"ðŸŒ± CO2 total estimado: {co2_total:.2f} kg")
        logger.info(f"â­ Preferencia promedio: {preferencia_total:.1f}%")
        
        # ===================================================================
        # CREAR SOLUCIÃ“N COMPLETA
        # ===================================================================
        
        fallback_solution = {
            'ruta_decodificada': ruta_ciclica,
            'objetivos': {
                'preferencia_total': preferencia_total,
                'costo_total': costo_total,
                'tiempo_total': tiempo_total,
                'distancia_total': distancia_total,
                'co2_total': co2_total,
                'sust_ambiental': sust_ambiental,
                'sust_economica': sust_economica, 
                'sust_social': sust_social,
                'riesgo_total': riesgo_total,
                'is_feasible': True
            },
            'is_feasible': True,
        }
        
        logger.info("ðŸŽ¯ SoluciÃ³n de respaldo generada exitosamente:")
        logger.info(f"   - Tipo: Ruta cÃ­clica completa")
        logger.info(f"   - POIs incluidos: {len(all_pois)}")
        logger.info(f"   - Ruta: {' â†’ '.join(map(str, ruta_ciclica))}")
        logger.info(f"   - Tiempo simulado: {total_wait_time}s")
        
        return fallback_solution

    def _format_optimized_sequence(
        self, 
        solution: Dict[str, Any],
        domain_payload
    ) -> list:
        """Formatea la secuencia optimizada para la respuesta."""
        
        sequence = []
        route = solution['ruta_decodificada']
        
        for poi_id in route:
            # Buscar POI
            matching_poi = next((p for p in domain_payload.pois if p.id == poi_id), None)
            
            if matching_poi:
                external_id = domain_payload.internal_to_external_ids.get(poi_id, poi_id)
                
                sequence.append({
                    'poi_id': int(external_id) if external_id.isdigit() else hash(external_id) % 10000,
                    'name': matching_poi.name,
                    'latitude': matching_poi.position[0],
                    'longitude': matching_poi.position[1],
                    'visit_order': len(sequence) + 1,
                    'estimated_visit_time': matching_poi.duracion_visita_min,
                    'arrival_time': f"{8 + len(sequence)}:00",
                    'departure_time': f"{8 + len(sequence) + 1}:30"
                })
        
        return sequence
